{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ba7c38b2-1103-4d28-8661-8f72f6d9b1f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# カタログやテーブルなどを作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bfb59f7c-6bcd-4f51-85f6-e291ff6aabaf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 利用するライブラリをインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46ec8bc8-ad4b-4a70-b780-5ffa89aae118",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install databricks-vectorsearch -q\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a001c5c-e8b7-46b6-b378-cf1badf2e8b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 共通設定の読み取り"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5396ddbd-cd47-4c59-a1aa-659aa70f79fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./00_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ecab5d9-a959-4c64-9e67-2a189df27e6d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## カタログとスキーマを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "858fc46a-96f7-4e29-ac70-9c1fd73c6417",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# カタログ作成。エラーとなった場合には、手動で作成してください。\n",
    "catalog_ddl = f\"CREATE CATALOG IF NOT EXISTS {catalog_name}\"\n",
    "print(catalog_ddl)\n",
    "_ = spark.sql(catalog_ddl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3676d8ed-8011-4c45-9dae-8fe29734ea03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# スキーマ作成\n",
    "schema_ddl = f\"CREATE SCHEMA IF NOT EXISTS {catalog_name}.{schema_name}\"\n",
    "print(schema_ddl)\n",
    "_ = spark.sql(schema_ddl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e25541ed-ec3b-4b04-b0d8-eed3e6310b5b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Volume の作成とデータの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "983adbd4-7722-4a95-9896-89a3d854031a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Volume 作成\n",
    "volume_ddl = f\"CREATE VOLUME IF NOT EXISTS {catalog_name}.{schema_name}.{volume_name}\"\n",
    "print(volume_ddl)\n",
    "_ = spark.sql(volume_ddl)\n",
    "\n",
    "# フォルダを作成\n",
    "print(\"source_dir: \", source_dir)\n",
    "dbutils.fs.mkdirs(source_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "935d3a9a-fea7-46b0-8ce5-53a1023d47de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# 現在の workspace の source_data 配下のオブジェクトを Volume のフォルダにコピー\n",
    "current_dir = os.getcwd()\n",
    "data_source_dir = os.path.join(current_dir, \"source_data\")\n",
    "print(os.listdir(data_source_dir))\n",
    "shutil.copytree(data_source_dir, py_source_dir, dirs_exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1694600-4374-436d-8164-6c4f41704849",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Volume に書かれたことを確認\n",
    "print(\"-- medalion_site.metadata.json\")\n",
    "metadata_file_path = source_dir + \"/landing/file_context\"\n",
    "metadata_file_path += \"/audit__ingest_timestamp=2025-10-14T10:07:33Z\"\n",
    "metadata_file_path += \"/medalion_site.metadata.json\"\n",
    "print(dbutils.fs.head(metadata_file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45a6c993-961b-4b7f-9aba-12c1e62c01d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## テーブルを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d74b632-5c2b-452d-bca8-b34b51340801",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "file_context_input_table_ddl = f\"\"\"\n",
    "CREATE OR REPLACE TABLE {catalog_name}.{schema_name}.{file_context_input_table_name}\n",
    "(\n",
    "    file_id STRING,\n",
    "    file_version STRING,\n",
    "    file_dir STRING,\n",
    "    file_name STRING,\n",
    "    file_sensitivity_label STRING,\n",
    "    file_url STRING,\n",
    "    file_extension STRING,\n",
    "    file_mime_type STRING,\n",
    "    size_in_bytes BIGINT,\n",
    "    raw_file_path STRING,\n",
    "    raw_file_path_by_service STRUCT < \n",
    "        databricks_volumes_file_path: STRING \n",
    "    >,\n",
    "    file_created_timestamp TIMESTAMP,\n",
    "    file_update_timestamp TIMESTAMP,\n",
    "    value STRING,\n",
    "    audit__ingest_timestamp TIMESTAMP,\n",
    "    audit__update_timestamp TIMESTAMP,\n",
    "    audit__delete_flg INT,\n",
    "    audit__source_delete_flg INT\n",
    ")\n",
    "TBLPROPERTIES (\n",
    "    delta.enableRowTracking = true\n",
    ")\n",
    "\"\"\"\n",
    "_ = spark.sql(file_context_input_table_ddl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a903e73-7bec-4dad-a77b-f2518d0fa69d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "file_info_table_ddl = f\"\"\"\n",
    "CREATE OR REPLACE TABLE {catalog_name}.{schema_name}.{file_info_table_name}\n",
    "(\n",
    "    row_id LONG,\n",
    "    raw_file_path STRING,\n",
    "    file_check STRUCT<\n",
    "        file_corrupt BOOLEAN\n",
    "    >,\n",
    "    file_md_content ARRAY<STRUCT<\n",
    "        slide_number INT,\n",
    "        slide_content STRING\n",
    "    >>,\n",
    "    audit__update_timestamp TIMESTAMP,\n",
    "    audit__delete_flg INT\n",
    ")\n",
    "TBLPROPERTIES (\n",
    "    delta.enableRowTracking = true\n",
    ")\n",
    "\"\"\"\n",
    "_ = spark.sql(file_info_table_ddl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe808a18-d538-410d-99c0-c516c8b84ed7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "file_context_output_table_ddl = f\"\"\"\n",
    "CREATE OR REPLACE TABLE {catalog_name}.{schema_name}.{file_context_output_table_name}\n",
    "(\n",
    "    file_id STRING,\n",
    "    file_version STRING,\n",
    "    file_dir STRING,\n",
    "    file_name STRING,\n",
    "    file_sensitivity_label STRING,\n",
    "    file_url STRING,\n",
    "    file_extension STRING,\n",
    "    file_mime_type STRING,\n",
    "    size_in_bytes BIGINT,\n",
    "    raw_file_path STRING,\n",
    "    raw_file_path_by_service STRUCT <\n",
    "        databricks_volumes_file_path: STRING\n",
    "    >,\n",
    "    file_path STRING,\n",
    "    file_path_by_service STRUCT <\n",
    "        databricks_volumes_file_path: STRING\n",
    "    >,\n",
    "    file_created_timestamp TIMESTAMP,\n",
    "    file_update_timestamp TIMESTAMP,\n",
    "    value STRING,\n",
    "    file_check STRUCT < \n",
    "        file_corrupt: BOOLEAN\n",
    "    >,\n",
    "    file_md_content ARRAY<STRUCT<\n",
    "        slide_number INT,\n",
    "        slide_content STRING\n",
    "    >>,\n",
    "    audit__ingest_timestamp TIMESTAMP,\n",
    "    audit__update_timestamp TIMESTAMP,\n",
    "    audit__delete_flg INT,\n",
    "    audit__source_delete_flg INT\n",
    ")\n",
    "TBLPROPERTIES (\n",
    "    delta.enableRowTracking = true\n",
    ")\n",
    "\"\"\"\n",
    "_ = spark.sql(file_context_output_table_ddl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d18e043-8383-4fd7-bb87-5de63c1a2ad7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "enriched_table_name_ddl = f\"\"\"\n",
    "CREATE OR REPLACE TABLE {catalog_name}.{schema_name}.{enriched_table_name}\n",
    "(\n",
    "    file_id STRING,\n",
    "    file_version STRING,\n",
    "    file_dir STRING,\n",
    "    file_name STRING,\n",
    "    file_sensitivity_label STRING,\n",
    "    file_url STRING,\n",
    "    file_extension STRING,\n",
    "    file_mime_type STRING,\n",
    "    size_in_bytes BIGINT,\n",
    "    raw_file_path STRING,\n",
    "    raw_file_path_by_service STRUCT <\n",
    "        databricks_volumes_file_path: STRING\n",
    "    >,\n",
    "    file_path STRING,\n",
    "    file_path_by_service STRUCT <\n",
    "        databricks_volumes_file_path: STRING\n",
    "    >,\n",
    "    file_created_timestamp TIMESTAMP,\n",
    "    file_update_timestamp TIMESTAMP,\n",
    "    value STRING,\n",
    "    file_check STRUCT < \n",
    "        file_corrupt: BOOLEAN\n",
    "    >,\n",
    "    file_md_content ARRAY<STRUCT<\n",
    "        slide_number INT,\n",
    "        slide_content STRING\n",
    "    >>,\n",
    "    audit__ingest_timestamp TIMESTAMP,\n",
    "    audit__update_timestamp TIMESTAMP,\n",
    "    audit__delete_flg INT,\n",
    "    audit__source_delete_flg INT\n",
    ")\n",
    "TBLPROPERTIES (\n",
    "    delta.enableRowTracking = true\n",
    ")\n",
    "\"\"\"\n",
    "_ = spark.sql(enriched_table_name_ddl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba01d92c-7ede-4ffb-b40d-7ae829c44872",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "enriched_table_name_ddl = f\"\"\"\n",
    "CREATE OR REPLACE TABLE {catalog_name}.{schema_name}.{enriched_table_name}\n",
    "(\n",
    "    file_id STRING,\n",
    "    file_version STRING,\n",
    "    file_dir STRING,\n",
    "    file_name STRING,\n",
    "    file_sensitivity_label STRING,\n",
    "    file_url STRING,\n",
    "    file_extension STRING,\n",
    "    file_mime_type STRING,\n",
    "    size_in_bytes BIGINT,\n",
    "    raw_file_path STRING,\n",
    "    raw_file_path_by_service STRUCT <\n",
    "        databricks_volumes_file_path: STRING\n",
    "    >,\n",
    "    file_path STRING,\n",
    "    file_path_by_service STRUCT <\n",
    "        databricks_volumes_file_path: STRING\n",
    "    >,\n",
    "    file_created_timestamp TIMESTAMP,\n",
    "    file_update_timestamp TIMESTAMP,\n",
    "    value STRING,\n",
    "    file_check STRUCT < \n",
    "        file_corrupt: BOOLEAN\n",
    "    >,\n",
    "    file_md_content ARRAY<STRUCT<\n",
    "        slide_number INT,\n",
    "        slide_content STRING\n",
    "    >>,\n",
    "    audit__ingest_timestamp TIMESTAMP,\n",
    "    audit__update_timestamp TIMESTAMP,\n",
    "    audit__delete_flg INT,\n",
    "    audit__source_delete_flg INT\n",
    ")\n",
    "TBLPROPERTIES (\n",
    "    delta.enableRowTracking = true\n",
    ")\n",
    "\"\"\"\n",
    "_ = spark.sql(enriched_table_name_ddl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b9f26b7-6cc1-4e7c-8b51-d08ca1159b87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "curated_table_name_ddl = f\"\"\"\n",
    "CREATE OR REPLACE TABLE {catalog_name}.{schema_name}.{curated_table_name}\n",
    "(\n",
    "    pk STRING,\n",
    "    file_id STRING,\n",
    "    slide_number INT,\n",
    "    file_url STRING,\n",
    "    image_path STRING,\n",
    "    slide_content STRING,\n",
    "    embedding ARRAY < DOUBLE >\n",
    ")\n",
    "TBLPROPERTIES (\n",
    "    delta.enableRowTracking = true,\n",
    "    delta.enableChangeDataFeed = true\n",
    ")\n",
    "\"\"\"\n",
    "_ = spark.sql(curated_table_name_ddl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0194055-ed4b-46be-8409-9a4e44593149",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Mosaic AI Vector Search のエンドポイントを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a0482fc-af1f-40a2-8170-c4d2b796eefe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Mosaic AI Vector Search のエンドポイントを作成。 10分程度かかるため、実行したまま次のノートブックに進んでください。\n",
    "from databricks.vector_search.client import VectorSearchClient\n",
    "\n",
    "client = VectorSearchClient()\n",
    "\n",
    "try:\n",
    "    client.get_endpoint(name=vector_search_name)\n",
    "    print(f\"[VS] endpoint '{vector_search_name}' は既存。ONLINE待機…\")\n",
    "    client.wait_for_endpoint(name=vector_search_name)\n",
    "except Exception:\n",
    "    print(f\"[VS] endpoint '{vector_search_name}' が未作成。作成します…\")\n",
    "    client.create_endpoint_and_wait(\n",
    "        name=vector_search_name,\n",
    "        endpoint_type=\"STANDARD\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f406632-cdac-4306-87dc-737856f35120",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    " # end"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7959959453659865,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "00_setup",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
